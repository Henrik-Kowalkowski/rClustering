---
title: "rClustering"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{rClustering}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message=FALSE}
library(rClustering)
library(dplyr)
library(tidyselect)
library(tidyr)
library(stringr)
library(ggplot2)
library(gridExtra)
library(kableExtra)
```

## Build the clusters
```{r}
clusts <- make_clusters(4, c_range = c(-20, 20), density = 500, categorical = F, seed = 1)
clusts %>%
  sample_n(10) %>%
  kable() %>%
  kable_material(c("striped", "hover"), full_width = F)
```

## Extract the cluster dimensions
```{r}
clust_positions <- clusts %>%
  group_by(y_true) %>%
  summarize_all(list(min = min, max = max, mean = mean)) %>%
  select(sort(peek_vars()))

clust_plot_data <- clust_positions %>%
  pivot_longer(cols = !y_true) %>%
  mutate(coord = if_else(str_detect(name, "^y_"), "y", "x")) %>%
  mutate(name = str_sub(name, start = 3)) %>%
  pivot_wider(names_from = coord, values_from = value) %>%
  mutate(center = factor(name == "mean"))

clust_plot_data %>%
  head() %>%
  kable() %>%
  kable_material(c("striped", "hover"), full_width = F)
```

## Plot the cluster dimensions and the cluster values
```{r fig.height = 4, fig.width = 8}
shapes <- c(16, 3)
names(shapes) <- c(F, T)
sizes <- c(3, 10)
names(sizes) <- c(F, T)

p1 <- clust_plot_data %>%
  ggplot(aes(x = x, y = y, col = y_true, shape = center, size = center)) +
  geom_point() +
  ggtitle("Cluster Dimensions") +
  coord_cartesian(xlim = c(-20, 20), ylim = c(-20, 20)) +
  scale_shape_manual(values = shapes) +
  scale_size_manual(values = sizes) +
  theme(legend.position = "none")

p2 <- clusts %>% ggplot(aes(x = x, y = y, col = y_true)) +
  geom_point() +
  ggtitle("Cluster Points") +
  coord_cartesian(xlim = c(-20, 20), ylim = c(-20, 20)) +
  theme(legend.position = "none")

grid.arrange(p1, p2, ncol = 2)
```
  
Since the clusters are perfect circles we can extract the center by taking the mean and the edges by taking the min and max of the coordinates.

## Fit Kmeans
```{r}
# Prepare clusters
clusts <- make_clusters(4, c_range = c(-20, 20), density = 500, categorical = F, seed = 2)

# Prepare arguments
vals <- setNames(data.frame(expand.grid(c(5, 10, 20), c(1, 10, 20))), c("n_iter", "n_start"))
vals$n_clust <- 4
vals$fit_name <- rep(c("A", "B", "C"), 3)

# Loop over argument combinations and fit Kmeans
out <- mapply(get_mean_clusters,
  fit_name = vals$fit_name,
  n_clust = vals$n_clust,
  iter = vals$n_iter,
  n_start = vals$n_start,
  MoreArgs = list(data = clusts, seed = 1),
  SIMPLIFY = F
) %>%
  bind_rows() %>%
  mutate(y_pred = factor(y_pred))
```


## Visualize fits
```{r fig.height = 12, fig.width = 7}
p1 <- ggplot(out, aes(x = x, y = y, col = y_true)) +
  geom_point(size = 0.5) +
  ggtitle("Ground Truth") +
  theme(legend.position = "none")

p2 <- ggplot(out, aes(x = x, y = y, col = y_pred)) +
  geom_point(size = 0.5) +
  facet_wrap(~title, labeller = labeller(title = label_wrap_gen(20)), ncol = 3) +
  ggtitle("Kmeans", subtitle = "Varying Iterations and Starts") +
  theme(legend.position = "none")

grid.arrange(p1, p2,
  widths = c(3, 4), heights = c(3, 9),
  layout_matrix = rbind(
    c(1, NA),
    c(3, 3)
  )
)
```
  
Note how important it is to use multiple starts so the model can converge. No amount of iterations will help if the starting point is very poor. Additionally, Kmeans is an unsupervised learning method. This means that it can find distinct clusters, but the clusters are not guaranteed to have the same label as the ground truth. The more iterations and starts specified the longer the fit takes.

